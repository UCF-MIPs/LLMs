{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450da648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "import re\n",
    "import torch\n",
    "import time\n",
    "from transformers import AutoTokenizer#, LlamaForCausalLM, LlamaTokenizer, BloomTokenizerFast, BloomForCausalLM\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ee4a1",
   "metadata": {},
   "source": [
    "### File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv('./labeled.csv')\n",
    "#df_main = df_main[df_main['stance'].notna()]\n",
    "#df_main['index'] = df_main.index\n",
    "#df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove emails\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]', '', text)\n",
    "    \n",
    "\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'&amp', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    text = text.replace('_', '')\n",
    "    text = text.replace('-', '')\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean_dataframe(df, column_name):\n",
    "    # Clean text in the specified column of the DataFrame\n",
    "    df[column_name] = df[column_name].apply(clean_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = clean_dataframe(df_main, 'text')\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487c23b",
   "metadata": {},
   "source": [
    "## GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fba91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f9066a",
   "metadata": {},
   "source": [
    "#### Check for the length of each article in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13072536",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "for i in range(len(df_main['text'])):\n",
    "    text = df_main['text'][i]\n",
    "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n",
    "    num_tokens = input_ids.shape[1]\n",
    "    if num_tokens >= 4000:\n",
    "        print(num_tokens, 'tokens at index:', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys = \"You are an expert in political science, political narratives, social media, disinformation and misinformation spread in social media. You can carefully read political articles and define the political narrative of each article. You are an expert in recognizing pro russian, anti russian, and neutral narratives.\"\n",
    "#question = \"What is the main political narrative of the given political article? \"\n",
    "#question = \"In 5 words, describe the main political narrative of the given political article? \"\n",
    "#question = \"Reply to me in a single word. Does the stance of the following article is pro-russian, anti-russian, or neutral? \"\n",
    "#question = \"Reply to me in a single word such as yes or no, and briefly explain your reasoning. Does this article contain the given political narrative or narratives? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d294c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Given the following news article: \"\n",
    "question1 = \". Reply to me in a single word only such as yes or no. Does the given article contain the following political narratives: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbcf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stance\n",
    "\n",
    "text = []\n",
    "for i in range(len(df_main)):\n",
    "    temp = question + \"The article: \" + df_main['text'][i]\n",
    "    text.append(temp)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12934317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narratives\n",
    "\n",
    "text = []\n",
    "for i in range(len(df_main)):\n",
    "    temp = question + df_main['text'][i] + question1 + df_main['narratives'][i] + \"?\"\n",
    "    text.append(temp)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b133f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating chat\n",
    "\n",
    "def chat(system, user_assistant):\n",
    "    assert isinstance(system, str), \"`system` should be a string\"\n",
    "    assert isinstance(user_assistant, list), \"`user_assistant` should be a list\"\n",
    "    system_msg = [{\"role\": \"system\", \"content\": system}]\n",
    "    user_assistant_msgs = [\n",
    "        {\"role\": \"assistant\", \"content\": user_assistant[i]} if i % 2 else {\"role\": \"user\", \"content\": user_assistant[i]}\n",
    "\n",
    "    for i in range(len(user_assistant))\n",
    "            ]\n",
    "    msgs = system_msg + user_assistant_msgs\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=msgs\n",
    "        )\n",
    "    status_code = response[\"choices\"][0][\"finish_reason\"]\n",
    "    assert status_code == \"stop\", f\"The status code was {status_code}.\"\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b11f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_ans = []\n",
    "for i in range(len(text)):\n",
    "    response_fn_test = chat(\n",
    "    sys,\n",
    "    [text[i]])\n",
    "    gpt_ans.append(response_fn_test)\n",
    "    print('index: ', i, 'response: ',  response_fn_test, '\\n')\n",
    "    time.sleep(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca164d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of job interruption, continue at certain index\n",
    "\n",
    "subset = df_main[16:]\n",
    "subset = subset.reset_index(drop = True)\n",
    "print(len(subset))\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_ans1 = []\n",
    "gpt_ans1 = gpt_ans\n",
    "print(len(gpt_ans1))\n",
    "print(gpt_ans1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_ans2 = []\n",
    "gpt_ans2 = gpt_ans\n",
    "print(len(gpt_ans2))\n",
    "print(gpt_ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_final = []\n",
    "gpt_final = gpt_ans1 + gpt_ans2\n",
    "print(len(gpt_final))\n",
    "print(gpt_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main['stance_gpt'] = gpt_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a7dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = clean_dataframe(df_main, 'stance_gpt')\n",
    "df_main['stance_gpt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['stance_gpt'] = df_main['stance_gpt'].map({'antirussian': 0, 'neutral': 1, 'prorussian': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054cabb",
   "metadata": {},
   "source": [
    "### Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c57886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(df_main['stance_enc'], df_main['stance_gpt'])\n",
    "\n",
    "cm_df = pd.DataFrame(cm)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_df,annot=True, fmt=\".1f\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nClassification Report:\\n', classification_report(df_main['stance_enc'], df_main['stance_gpt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.to_csv('df_main_LLMs.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624fa48",
   "metadata": {},
   "source": [
    "## BART + PALM 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a6c20",
   "metadata": {},
   "source": [
    "### BART Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "bart_pretrained = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78725675",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(df_main)):\n",
    "    input_tokens = tokenizer.batch_encode_plus([df_main['text'][i]], return_tensors = 'pt', max_length = 1024, truncation = True)['input_ids']\n",
    "\n",
    "    encoded_ids = bart_pretrained.generate(input_tokens,\n",
    "                                      num_beams = 4,\n",
    "                                      length_penalty = 2.0,\n",
    "                                      max_length = 497,\n",
    "                                      min_length = 497,\n",
    "                                      no_repeat_ngram_size = 3)\n",
    "    summary = tokenizer.decode(encoded_ids.squeeze(), skip_special_tokens = True)\n",
    "    result.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['summary'] = result\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df5289",
   "metadata": {},
   "source": [
    "### PALM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm\n",
    "\n",
    "palm.configure(api_key = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "def make_prompt(query, relevant_passage):\n",
    "    escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \").replace(\".\", \"\").replace('\"', \"\")\n",
    "    prompt = textwrap.dedent(\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "  Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "  However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "  strike a friendly and converstional tone.\n",
    "  QUESTION: '{query}'\n",
    "  PASSAGE: '{relevant_passage}'\n",
    "\n",
    "    ANSWER:\n",
    "  \"\"\").format(query=query, relevant_passage=escaped)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"Provide a single word answer only. Does the stance of the following article is pro-russian, anti-russian, or neutral? \"\n",
    "#query = \"Give me the main political narratives of the given political article? Be concise. \"\n",
    "#query = \"In one sentence only, describe the main political narrative of the following article. \"\n",
    "\n",
    "question = \"Given the following news article: \"\n",
    "question1 = \". Reply to me in a single word only such as yes or no. Does the given article contain the following political narratives: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in range(len(df_main)):\n",
    "    temp = question + df_main['text'][i] + question1 + df_main['narratives'][i] + \"?\"\n",
    "    text.append(temp)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa81b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "text = []\n",
    "for i in range(len(df_main)):\n",
    "    prompt = make_prompt(query, df_main['text'][i])\n",
    "    text.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f758f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "text_model = text_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.5\n",
    "\n",
    "answers = []\n",
    "for i in range(len(df_main)):\n",
    "    answer = palm.generate_text(prompt = text[i],\n",
    "                                model = text_model,\n",
    "                                candidate_count = 1,\n",
    "                                temperature = temperature,\n",
    "                                max_output_tokens = 1024,)\n",
    "    time.sleep(3)\n",
    "    #for i, candidate in enumerate(answer.candidates):\n",
    "        #print(f\"Candidate {i}: {candidate['output']}\\n\")\n",
    "        #if candidate['output'] == '':\n",
    "            #answers.append('none')\n",
    "    answers.append(answer.result)\n",
    "    print('index: ', i, 'response: ', answer.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"PALM_narratives\"] = answers\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a578bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nones = df_main[~df_main[\"PALM_narratives\"].notna()]\n",
    "df_main = df_main[df_main[\"PALM_narratives\"].notna()]\n",
    "print(len(nones))\n",
    "print(len(df_main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"PALM_narratives\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a963344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['PALM_narratives_enc'] = df_main['PALM_narratives'].map({'yes': 1, 'no': 0})\n",
    "df_main[\"PALM_narratives_enc\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['PALM_stance_enc'] = df_main['PALM_stance'].map({'anti-russian': 0, 'pro-russian': 2, 'neutral': 1})\n",
    "df_main[\"PALM_stance_enc\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789679a8",
   "metadata": {},
   "source": [
    "### Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(df_main[\"stance_enc\"], df_main['PALM_stance'])\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index = ['Anti-Russian','Neutral','Pro-Russian'], \n",
    "                     columns = ['Anti-Russian','Neutral','Pro-Russian'])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_df,annot=True, fmt=\".1f\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4573a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nClassification Report:\\n', classification_report(df_main['stance_enc'], df_main['PALM_stance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.to_csv('df_main_LLMs.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
