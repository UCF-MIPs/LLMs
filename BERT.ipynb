{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW, BertModel, BertTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd32ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv('./labeled.csv')\n",
    "df_unlabeled = pd.read_csv('./unlabeled.csv')\n",
    "#df_main = df_main[df_main['stance'].notna()]\n",
    "#df_main['index'] = df_main.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove emails\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]', '', text)\n",
    "    \n",
    "\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'&amp', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    text = text.replace('_', '')\n",
    "    text = text.replace('-', '')\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean_dataframe(df, column_name):\n",
    "    # Clean text in the specified column of the DataFrame\n",
    "    df[column_name] = df[column_name].apply(clean_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "df_main = clean_dataframe(df_main, 'text')\n",
    "df_unlabeled = clean_dataframe(df_unlabeled, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d954c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "df_main[\"stance_enc\"] = le.fit_transform(df_main[\"stance\"])\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd267a",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_train = df_main.groupby(['stance_enc']).apply(lambda grp: grp.sample(n=33))\n",
    "loaded_val = df_main.groupby(['stance_enc']).apply(lambda grp: grp.sample(n=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, labels_col, text_col, pretrained='bert-large-uncased'):\n",
    "        self.labels_col = labels_col\n",
    "        self.labels = df[self.labels_col].to_list()\n",
    "        self.text_col = text_col\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained) \n",
    "        self.texts = [self.tokenizer(text, padding = 'max_length', max_length = 512, truncation = True,\n",
    "                                return_tensors = 'pt') for text in df[self.text_col]]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y\n",
    "\n",
    "    \n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.5, pretrained='bert-base-uncased'):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.bert = BertModel.from_pretrained(pretrained)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, self.num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        outputs = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        pooled_output = outputs[1]\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_output = self.softmax(linear_output)\n",
    "        return final_output\n",
    "    \n",
    "class Train():\n",
    "    def __init__(self, model, train_data, train_col, labels_col, val_data, criterion, optimizer, epochs, batch_size, retrain, model_path):\n",
    "        self.model = model\n",
    "        self.train_data = train_data\n",
    "        self.train_col = train_col\n",
    "        self.labels_col = labels_col\n",
    "        self.val_data = val_data\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.retrain = retrain\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def train_plots(self, epochs_list, train_losses, val_losses, train_accs, val_accs):\n",
    "        get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "        sns.set(rc={'figure.figsize':(19, 9)})\n",
    "        fig, ax = plt.subplots(1,2)\n",
    "        ax[0].plot(epochs_list, train_losses, label = 'Training Loss', marker='o')\n",
    "        ax[0].plot(epochs_list, val_losses, label = 'Validation Loss', marker='o')\n",
    "        ax[0].set_title('Loss Values')\n",
    "        ax[0].set_xlabel('Epoch')\n",
    "        ax[0].set_ylabel('Value')\n",
    "        ax[1].plot(epochs_list, train_accs, label = 'Training Accuracy', marker='o')\n",
    "        ax[1].plot(epochs_list, val_accs, label = 'Validation Accuracy', marker='o')\n",
    "        ax[1].set_title('Accuracy Values')\n",
    "        ax[1].set_xlabel('Epoch')\n",
    "        ax[1].set_ylabel('Percent (%)')\n",
    "        ax[0].legend()\n",
    "        ax[1].legend()\n",
    "        plt.show()\n",
    "        fig.savefig('./plots/train-val-loss-accs.png')\n",
    "\n",
    "    def start_train(self):\n",
    "        train, val = Dataset(self.train_data, self.labels_col, self.train_col), Dataset(self.val_data, self.labels_col, self.train_col)\n",
    "        train_dataloader = torch.utils.data.DataLoader(train, self.batch_size, shuffle = True)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val, self.batch_size)\n",
    "        \n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        print('CUDA:', use_cuda)\n",
    "        device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "        if use_cuda:\n",
    "            self.model = self.model.to(device)\n",
    "            self.criterion = self.criterion.to(device)\n",
    "            \n",
    "        total_steps = len(train_dataloader)*self.epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(self.optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "        if self.retrain == True:\n",
    "            self.model.load_state_dict(torch.load(self.model_path, map_location = 'cpu'))\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        epochs_list = []\n",
    "        \n",
    "\n",
    "        for epoch_num in range(self.epochs):\n",
    "            print('\\n====================== Epoch {:} / {:} =====================\\n'.format(epoch_num + 1, self.epochs))\n",
    "            total_loss_train = 0\n",
    "            total_acc_train = 0\n",
    "            self.model.train()\n",
    "            for train_input, train_label in tqdm(train_dataloader, desc=f\"Training Epoch {epoch_num + 1}\"):\n",
    "                train_label = train_label.type(torch.LongTensor)\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = self.model(input_id, mask)\n",
    "\n",
    "                batch_loss = self.criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "\n",
    "                acc_tr = (output.argmax(dim = 1) == train_label).sum().item()\n",
    "                total_acc_train += acc_tr\n",
    "                \n",
    "                self.model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            # Validation\n",
    "            total_loss_val = 0\n",
    "            total_acc_val = 0\n",
    "            \n",
    "            self.model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_input, val_label in val_dataloader:\n",
    "                    val_label = val_label.type(torch.LongTensor)\n",
    "                    val_label = val_label.to(device)\n",
    "                        \n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = self.model(input_id, mask)\n",
    "                    #label_ids = val_label.to('cpu').numpy()\n",
    "                    \n",
    "                    batch_loss = self.criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc_val = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc_val\n",
    "\n",
    "            train_loss = total_loss_train / len(train_dataloader)\n",
    "            val_loss = total_loss_val / len(val_dataloader)\n",
    "            train_acc = total_acc_train / len(train)\n",
    "            val_acc = total_acc_val / len(val)\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "            epochs_list.append(epoch_num + 1)\n",
    "\n",
    "            self.train_plots(epochs_list, train_losses, val_losses, train_accs, val_accs)\n",
    "\n",
    "            print(f'Epoch {epoch_num + 1} / {self.epochs}')\n",
    "            print(f'Train Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "            print(f'Val Loss: {val_loss:.3f} | Val Acc: {val_acc * 100:.2f}%')\n",
    "\n",
    "        # Save the final model\n",
    "        if self.retrain == False:\n",
    "            torch.save(self.model.state_dict(), './bert_base.pth')\n",
    "            print('Base model has been saved!')\n",
    "        else:\n",
    "            torch.save(self.model.state_dict(), './bert_retrained.pth')\n",
    "            print('Retrained model has been saved!')\n",
    "\n",
    "\n",
    "class UnseenDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, text_col, pretrained='bert-large-uncased'):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained)\n",
    "        self.texts = self.tokenizer(df[text_col].tolist(),\n",
    "                                    padding='max_length',\n",
    "                                    max_length=512,\n",
    "                                    truncation=True,\n",
    "                                    return_tensors='pt')\n",
    "                                    \n",
    "    def __len__(self):\n",
    "        return self.texts['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: tensor[idx] for key, tensor in self.texts.items()}\n",
    "\n",
    "class Test():\n",
    "    def __init__(self, model, test_data, labels_col, batch_size, is_multi_label=False):\n",
    "        self.model = model\n",
    "        self.test_data = test_data\n",
    "        self.labels_col = labels_col\n",
    "        self.batch_size = batch_size\n",
    "        self.is_multi_label = is_multi_label\n",
    "\n",
    "    def plot_metrics(self, labels, outputs):\n",
    "        labels = np.concatenate(labels)\n",
    "        outputs = F.softmax(torch.cat(outputs), dim=1).cpu().numpy()\n",
    "        preds = outputs[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(labels, preds)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        if self.is_multi_label:\n",
    "            roc_auc = roc_auc_score(labels, outputs, multi_class='ovr')\n",
    "            print('ROC AUC Score: ', roc_auc)\n",
    "        \n",
    "        y_pred = np.where(preds > 0.5, 1, 0)\n",
    "        print('\\nClassification Report:\\n', classification_report(labels, y_pred))\n",
    "        cm = confusion_matrix(labels, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(9, 6))\n",
    "        plt.plot(fpr, tpr, 'b', label=f'AUC = {roc_auc:.2f}')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.savefig('./plots/roc-curve.png')\n",
    "        plt.show()\n",
    "        \n",
    "        cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        cm_disp.plot()\n",
    "\n",
    "    def start_test(self):\n",
    "        test_dataset = Dataset(self.test_data, self.labels_col)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, self.batch_size)\n",
    "\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "        if use_cuda:\n",
    "            self.model = self.model.cuda()\n",
    "        self.model.eval()\n",
    "        total_acc_test = 0\n",
    "        test_outputs = []\n",
    "        test_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for test_input, test_label in test_dataloader:\n",
    "                test_label = test_label.type(torch.LongTensor).to(device)\n",
    "                mask = test_input['attention_mask'].to(device)\n",
    "                input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = self.model(input_id, mask)\n",
    "                acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "                total_acc_test += acc\n",
    "                \n",
    "                test_labels.append(test_label.cpu().numpy())\n",
    "                test_outputs.append(output)\n",
    "                \n",
    "        self.plot_metrics(test_labels, test_outputs)\n",
    "        print(f'Test Accuracy: {total_acc_test / len(self.test_data) * 100:.3f} %')\n",
    "\n",
    "\n",
    "class Predict():\n",
    "    def __init__(self, model, model_path, unseen_data, labels_col, text_col, original_idx, batch_size):\n",
    "        self.model = model\n",
    "        self.model_path = model_path\n",
    "        self.unseen_data = unseen_data\n",
    "        self.labels_col = labels_col\n",
    "        self.text_col = text_col\n",
    "        self.original_idx = original_idx\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def start_predict(self):\n",
    "        test_dataset = UnseenDataset(self.unseen_data, self.text_col)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, self.batch_size, shuffle=False)\n",
    "        \n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        print('CUDA:', use_cuda)\n",
    "        device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "        if use_cuda:\n",
    "            self.model = self.model.to(device)\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(self.model_path, map_location=device))\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for test_input in test_dataloader:\n",
    "                mask = test_input['attention_mask'].to(device)\n",
    "                input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "                output = self.model(input_id, mask)\n",
    "                predictions.append(output.cpu().numpy())\n",
    "                \n",
    "        predictions = np.concatenate(predictions, axis=0)\n",
    "        self.unseen_data[self.labels_col] = predictions.argmax(axis=1).astype(int)\n",
    "        predicted_data = self.unseen_data[[self.original_idx, self.text_col, self.labels_col]]\n",
    "        predicted_data.to_csv('predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertClassifier(num_classes = 3)\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5, eps = 1e-8) #1e-3 bad, 1e-5 better, 2e-3 bad # 2e-5  good for binary\n",
    "loss_func = nn.CrossEntropyLoss()   \n",
    "epochs = 5\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352399b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTrain/Validation: \\n', len(loaded_train), '/', len(loaded_val))\n",
    "train = Train(model, loaded_train, 'text', 'stance_enc', loaded_val, loss_func, optimizer, epochs, batch_size, False, '') \n",
    "train.start_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2fc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = df_unlabeled\n",
    "unseen_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86faa1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './bert_base.pth'\n",
    "unseen_data = df_unlabeled\n",
    "\n",
    "predict = Predict(model, model_path, unseen_data, 'stance_enc', 'text', 'index1', batch_size)\n",
    "predict.start_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e36bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted  = pd.read_csv('predicted.csv')\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad4c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted['stance_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43897e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([predicted, df_main[['index1', 'text', 'stance_enc']]], axis = 0)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['stance_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dfaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = clean_dataframe(combined_data, 'text')\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = np.split(combined_data.sample(frac=1, random_state=42), [int(.8 * len(combined_data)), int(.9 * len(combined_data))])\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_val))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['stance_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_train = df_train\n",
    "loaded_val = df_val\n",
    "loaded_test = df_test\n",
    "\n",
    "model = BertClassifier(num_classes = 3)\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5, eps = 1e-8)\n",
    "loss_func = nn.CrossEntropyLoss()   \n",
    "epochs = 5\n",
    "batch_size =  16\n",
    "model_path = './bert_base.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTrain/Validation: \\n', len(loaded_train), '/', len(loaded_val))\n",
    "train = Train(model, loaded_train, 'text', 'stance_enc', loaded_val, loss_func, optimizer, epochs, batch_size, True, model_path) \n",
    "train.start_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test():\n",
    "    def __init__(self, model, test_data, labels_col, train_col, batch_size, multi_label):\n",
    "        self.model = model\n",
    "        self.test_data = test_data\n",
    "        self.batch_size = batch_size\n",
    "        self.labels_col = labels_col\n",
    "        self.train_col = train_col\n",
    "        self.multi_label = multi_label\n",
    "        \n",
    "    def plot_metrics(self, labels, outputs):\n",
    "        labels = torch.cat(labels, dim = 0).cpu().numpy()\n",
    "        outputs = torch.cat(outputs, dim = 0)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim = 1).cpu().numpy()\n",
    "        preds = probs[:, 1]\n",
    "       \n",
    "        # Classification Report\n",
    "        y_pred = np.where(preds > 0.5, 1, 0)\n",
    "        \n",
    "        print('\\nClassification Report:\\n', classification_report(labels, y_pred))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(labels, y_pred)\n",
    "        cm_df = pd.DataFrame(cm)\n",
    "        sns.heatmap(cm_df, annot=True, fmt=\".1f\")\n",
    "\n",
    "    def start_test(self):\n",
    "        test = Dataset(self.test_data, self.labels_col, self.train_col)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test, self.batch_size)\n",
    "\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "        self.model = self.model.to(device)\n",
    "\n",
    "        self.model.eval()\n",
    "        total_acc_test = 0\n",
    "        test_outputs = []\n",
    "        test_labels = []\n",
    "        with torch.no_grad():\n",
    "            for test_input, test_label in test_dataloader:\n",
    "                test_label = test_label.type(torch.LongTensor).to(device)\n",
    "                mask = test_input['attention_mask'].to(device)\n",
    "                input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = self.model(input_id, mask)\n",
    "                acc = (output.argmax(dim = 1) == test_label).sum().item()\n",
    "                total_acc_test += acc\n",
    "                \n",
    "                test_labels.append(test_label.cpu())\n",
    "                test_outputs.append(output.cpu())\n",
    "        self.plot_metrics(test_labels, test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db138340",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Test(model, loaded_test, 'stance_enc', 'text', batch_size, True)\n",
    "test.start_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
